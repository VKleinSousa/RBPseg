{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9884508d-a28c-422a-b680-517bf461d9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23738146222086268"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Specify the file path\n",
    "path = './data/hmmvsuniprot/expanded_240904/'\n",
    "# Get a list of all .txt files in the folder\n",
    "txt_files = glob.glob(os.path.join(path, '*.txt'))\n",
    "\n",
    "# Define column names and their widths\n",
    "col_names = ['target_name', 'accession_1', 'query_name', 'accession_2', \n",
    "             'E-value_1', 'score_1', 'bias_1', 'E-value_2', 'score_2', \n",
    "             'bias_2', 'exp', 'reg', 'clu', 'ov', 'env', 'dom', 'rep', \n",
    "             'inc', 'description']\n",
    "\n",
    "col_widths = [31, 11, 21, 11, 9, 7, 7, 9, 7, 7, 5, 5, 4, 4, 4, 4, 4, 4, 100]\n",
    "\n",
    "concatenated_df = pd.DataFrame()\n",
    "for file_path in txt_files:\n",
    "# Read the file into a DataFrame\n",
    "    df = pd.read_fwf(file_path, widths=col_widths, names=col_names, skiprows=5,skipfooter=10)\n",
    "    df = df[df['E-value_1'] < 10e-10]\n",
    "    df = df[df['E-value_2'] < 10e-10]\n",
    "    concatenated_df = pd.concat([df, concatenated_df], ignore_index=True)\n",
    "\n",
    "\n",
    "concatenated_df['TC'] = 'TC' + concatenated_df['query_name'].str.split('_').str[1]\n",
    "\n",
    "# Sort the DataFrame based on 'E-value_1' column in ascending order\n",
    "df_sorted = concatenated_df.sort_values(by='E-value_1')\n",
    "\n",
    "# Keep the row with the smallest 'E-value_1'\n",
    "df_unique = df_sorted.drop_duplicates(subset='target_name', keep='first')\n",
    "\n",
    "sum(df_unique['query_name'].value_counts()/16345 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c4190b-aec8-45e3-9e23-629090c99562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/8071jp1s2ml2vj_81_qt_5680000gn/T/ipykernel_60845/1987612710.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['accession_code'] = df_unique['target_name'].str.split('|').str.get(1)\n"
     ]
    }
   ],
   "source": [
    "#df_sorted = df_sorted.groupby('target_name').apply(sum_encoded_TC)\n",
    "df_unique['accession_code'] = df_unique['target_name'].str.split('|').str.get(1)\n",
    "df_sorted['accession_code'] = df_sorted['target_name'].str.split('|').str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e57665-33e7-4df8-b9b5-cc23f38da653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/8071jp1s2ml2vj_81_qt_5680000gn/T/ipykernel_60845/1678470974.py:9: DeprecationWarning: Using 'method_whitelist' with Retry is deprecated and will be removed in v2.0. Use 'allowed_methods' instead\n",
      "  retry_strategy = Retry(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 accession codes so far...\n",
      "Processed 200 accession codes so far...\n",
      "Processed 300 accession codes so far...\n",
      "Processed 400 accession codes so far...\n",
      "Processed 500 accession codes so far...\n",
      "Processed 600 accession codes so far...\n",
      "Processed 700 accession codes so far...\n",
      "Processed 800 accession codes so far...\n",
      "Processed 900 accession codes so far...\n",
      "Processed 1000 accession codes so far...\n",
      "Processed 1100 accession codes so far...\n",
      "Processed 1200 accession codes so far...\n",
      "Processed 1300 accession codes so far...\n",
      "Processed 1400 accession codes so far...\n",
      "Processed 1500 accession codes so far...\n",
      "Processed 1600 accession codes so far...\n",
      "Processed 1700 accession codes so far...\n",
      "Processed 1800 accession codes so far...\n",
      "Processed 1900 accession codes so far...\n",
      "Processed 2000 accession codes so far...\n",
      "Processed 2100 accession codes so far...\n",
      "Processed 2200 accession codes so far...\n",
      "Processed 2300 accession codes so far...\n",
      "Processed 2400 accession codes so far...\n",
      "Processed 2500 accession codes so far...\n",
      "Processed 2600 accession codes so far...\n",
      "Processed 2700 accession codes so far...\n",
      "Processed 2800 accession codes so far...\n",
      "Processed 2900 accession codes so far...\n",
      "Processed 3000 accession codes so far...\n",
      "Processed 3100 accession codes so far...\n",
      "Processed 3200 accession codes so far...\n",
      "Processed 3300 accession codes so far...\n",
      "Processed 3400 accession codes so far...\n",
      "Processed 3500 accession codes so far...\n",
      "Processed 3600 accession codes so far...\n",
      "Processed 3700 accession codes so far...\n",
      "Processed 3800 accession codes so far...\n",
      "Processed 3900 accession codes so far...\n",
      "Processed 4000 accession codes so far...\n",
      "Processed 4100 accession codes so far...\n",
      "Processed 4200 accession codes so far...\n",
      "Processed 4300 accession codes so far...\n",
      "Processed 4400 accession codes so far...\n",
      "Processed 4500 accession codes so far...\n",
      "Processed 4600 accession codes so far...\n",
      "Processed 4700 accession codes so far...\n",
      "Processed 4800 accession codes so far...\n",
      "Processed 4900 accession codes so far...\n",
      "Processed 5000 accession codes so far...\n",
      "Processed 5100 accession codes so far...\n",
      "Processed 5200 accession codes so far...\n",
      "Processed 5300 accession codes so far...\n",
      "Processed 5400 accession codes so far...\n",
      "Processed 5500 accession codes so far...\n",
      "Processed 5600 accession codes so far...\n",
      "Processed 5700 accession codes so far...\n",
      "Processed 5800 accession codes so far...\n",
      "Processed 5900 accession codes so far...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# Setup a retry strategy to avoid rate limiting and network issues\n",
    "retry_strategy = Retry(\n",
    "    total=5,  # Total retries before giving up\n",
    "    backoff_factor=1,  # Wait 1, 2, 4, 8, etc. seconds between retries\n",
    "    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these HTTP statuses\n",
    "    method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"]  # Retry on these HTTP methods\n",
    ")\n",
    "\n",
    "# Mount retry strategy to requests session\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "# Function to find subfamily (with retry handling)\n",
    "def find_subfamily(uniprot_id):\n",
    "    fasta_url = f'https://rest.uniprot.org/uniprotkb/{uniprot_id}.txt'\n",
    "    \n",
    "    try:\n",
    "        response = session.get(fasta_url, timeout=1000)  # Use session with retry\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        text = response.text  # Get the text content from the response\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error: Unable to retrieve information from {fasta_url}\")\n",
    "        text = None\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "        text = None\n",
    "    except requests.exceptions.ConnectionError as err:\n",
    "        print(f\"Connection error: {err}\")\n",
    "        text = None\n",
    "    \n",
    "    if text:\n",
    "        # Define the pattern to extract the taxonomy information\n",
    "        taxonomy_pattern = r'OC\\s+([\\w\\s;]+)\\.'\n",
    "    \n",
    "        # Find all matches of the pattern in the text\n",
    "        taxonomy_matches = re.findall(taxonomy_pattern, text)\n",
    "        \n",
    "        # Check if matches were found\n",
    "        if taxonomy_matches:\n",
    "            # Combine multiple lines into a single string and split by semicolon\n",
    "            taxonomy_string = ' '.join(taxonomy_matches)\n",
    "            taxonomy_levels = [level.strip() for level in taxonomy_string.split(';')]\n",
    "    \n",
    "            # Iterate through the list and find the string containing 'virinae'\n",
    "            desired_string = None\n",
    "            for level in taxonomy_levels:\n",
    "                if 'viridae' in level:\n",
    "                    desired_string = level.replace('OC', '').replace(' ', '')\n",
    "                    break  # Stop searching once found\n",
    "                elif 'virinae' in level:\n",
    "                    desired_string = level.replace('OC', '').replace(' ', '')\n",
    "                    break  # Stop searching once found\n",
    "                    \n",
    "            return desired_string if desired_string else \"unclassified\"\n",
    "    \n",
    "    return \"unclassified\"\n",
    "    \n",
    "\n",
    "# Function to process each accession code in parallel\n",
    "def process_accession_code(accession_code):\n",
    "    return accession_code, find_subfamily(accession_code)\n",
    "\n",
    "# List to store subfamilies\n",
    "subfamilies_sorted = {}\n",
    "\n",
    "# Number of workers (threads)\n",
    "num_workers = 12  # You can adjust this based on the number of CPUs/threads available\n",
    "\n",
    "# Counter to track the progress\n",
    "counter = 0\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel execution\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks for each accession code\n",
    "    futures = {executor.submit(process_accession_code, acc): acc for acc in df_sorted['accession_code']}\n",
    "    \n",
    "    # Process completed futures as they finish\n",
    "    for future in as_completed(futures):\n",
    "        accession_code, subfam = future.result()\n",
    "        subfamilies_sorted[accession_code] = subfam\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "        \n",
    "        # Print a progress message every 100 processed accession codes\n",
    "        if counter % 100 == 0:\n",
    "            print(f\"Processed {counter} accession codes so far...\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0aa4761-948e-40d9-9c8c-c9bbfa3b9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/8071jp1s2ml2vj_81_qt_5680000gn/T/ipykernel_60845/1669326041.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['subfamilies'] = df_unique['accession_code'].map(subfamilies_sorted)\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_sorted.drop_duplicates(subset='target_name', keep='first')\n",
    "#df_unique['subfamilies'] = subfamilies\n",
    "df_sorted['subfamilies'] = df_sorted['accession_code'].map(subfamilies_sorted)\n",
    "df_unique['subfamilies'] = df_unique['accession_code'].map(subfamilies_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0973ea7-e938-486c-8158-0a7a6e91fa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/8071jp1s2ml2vj_81_qt_5680000gn/T/ipykernel_60845/1133573331.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['cluster']=df_filtered['TC'].str.replace('TC','').astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_sorted[df_sorted['E-value_1']<1.0e-10]\n",
    "df_filtered['cluster']=df_filtered['TC'].str.replace('TC','').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ead7fff-3933-4131-b593-e94ea2b99e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Protein_ID\", \"MD5\", \"Length\", \"Database\", \"Signature\", \"Signature_Desc\", \n",
    "    \"Start\", \"End\", \"Score\", \"Status\", \"Date\", \"InterPro_ID\", \n",
    "    \"InterPro_Desc\", \"GO_Terms\", \"Pathways\"\n",
    "]\n",
    "df_interpro = pd.read_csv('./data/interpro/output_file_interpro.tsv', sep='\\t', names=column_names, header=None)\n",
    "df_pfam = df_interpro[df_interpro[\"Database\"].isin(['Gene3D','Pfam','CDD','FunFam'])]\n",
    "df_pfam  = df_pfam [df_pfam ['Score'].astype(float) < 10e-5]\n",
    "\n",
    "\n",
    "\n",
    "df_pfam['Extracted'] = df_pfam['Protein_ID'].str.extract(r'^..([a-z0-9]+)')[0].str.upper()\n",
    "def remove_duplicate_string(s):\n",
    "    pattern = r'(.+?)\\1+$'  # Captures repeated patterns\n",
    "    match = re.match(pattern, s)\n",
    "    return match.group(1) if match else s\n",
    "\n",
    "# Apply the function to the 'Extracted' column\n",
    "df_pfam ['accession_code'] = df_pfam['Extracted'].apply(remove_duplicate_string)\n",
    "\n",
    "#mapping = dict(zip(df_cleaned['Protein_base'], df_cleaned['fold']))\n",
    "#df_pfam['Protein_ID_2'] = df_pfam['Protein_ID'].str.split('_').str[0]\n",
    "#df_pfam['fold']=df_pfam['Protein_ID_2'].map(mapping).fillna('unknown')\n",
    "#df_pfam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a15aeb-c415-4396-8403-66df853df980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with full outer join\n",
    "df_merged_interpro = pd.merge(df_filtered, df_pfam, on='accession_code', how='outer')\n",
    "# Filter rows where 'target_name' is NaN\n",
    "df_merged_interpro = df_merged_interpro[df_merged_interpro['target_name'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a214c5d-4fc0-4110-9259-04ca92b85dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_name', 'accession_1', 'query_name', 'accession_2', 'E-value_1',\n",
       "       'score_1', 'bias_1', 'E-value_2', 'score_2', 'bias_2', 'exp', 'reg',\n",
       "       'clu', 'ov', 'env', 'dom', 'rep', 'inc', 'description', 'TC',\n",
       "       'accession_code', 'subfamilies', 'cluster', 'Protein_ID', 'MD5',\n",
       "       'Length', 'Database', 'Signature', 'Signature_Desc', 'Start', 'End',\n",
       "       'Score', 'Status', 'Date', 'InterPro_ID', 'InterPro_Desc', 'GO_Terms',\n",
       "       'Pathways', 'Extracted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_interpro.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b59d678-9474-4dcf-b205-716ddf6d3594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TC Accession Code                                        description  \\\n",
      "0   TC3     A0A653FW15  Phage tail fiber protein OS=Escherichia phage ...   \n",
      "1   TC4     A0A653FW15  Phage tail fiber protein OS=Escherichia phage ...   \n",
      "2   TC9     A0A653FW15  Phage tail fiber protein OS=Escherichia phage ...   \n",
      "3   TC0     A0A5Q2F504  Long tail fiber proximal subunit OS=Klebsiella...   \n",
      "4  TC14     A0A5Q2F504  Long tail fiber proximal subunit OS=Klebsiella...   \n",
      "\n",
      "  Family/Subfamily  E-value (TC-HMM) Database Signature Signature_Desc  Start  \\\n",
      "0     unclassified      0.000000e+00      NaN       NaN            NaN    NaN   \n",
      "1     unclassified      0.000000e+00      NaN       NaN            NaN    NaN   \n",
      "2     unclassified      1.500000e-31      NaN       NaN            NaN    NaN   \n",
      "3    Straboviridae      0.000000e+00      NaN       NaN            NaN    NaN   \n",
      "4    Straboviridae      6.600000e-12      NaN       NaN            NaN    NaN   \n",
      "\n",
      "   End E-value (InterPro) InterPro_ID  \n",
      "0  NaN                NaN         NaN  \n",
      "1  NaN                NaN         NaN  \n",
      "2  NaN                NaN         NaN  \n",
      "3  NaN                NaN         NaN  \n",
      "4  NaN                NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your existing DataFrame (assuming it's already loaded)\n",
    "selected_columns = ['TC', 'accession_code', 'description', 'subfamilies', 'E-value_1', 'Database', 'Signature', 'Signature_Desc', 'Start', 'End',\n",
    "       'Score', 'InterPro_ID', ]\n",
    "\n",
    "# Create a new DataFrame with only the selected columns and rename them in one step\n",
    "df_selected = df_merged_interpro[selected_columns].rename(columns={\n",
    "    'accession_code': 'Accession Code',\n",
    "    'subfamilies': 'Family/Subfamily',\n",
    "    'E-value_1': 'E-value (TC-HMM)',\n",
    "    'Score': 'E-value (InterPro)',\n",
    "    'description_y': 'Protein Description',\n",
    "    'Names': 'Phage'\n",
    "})\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(df_selected.head())  # Show the first few rows\n",
    "\n",
    "\n",
    "df_selected.to_csv('./data/data_expanded_interpro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e07d5b-7f74-4507-8efb-2b3ff6760fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered = df_filtered[ df_sorted['subfamilies']!= 'unclassified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20aec813-20d2-4207-a698-f56102e28698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenated_df[concatenated_df['TC']=='TC16'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0abe14-3376-453a-b7a6-28153425c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Specify the file path\n",
    "path = './data/hmmvsuniprot/domain_hmm/'\n",
    "# Get a list of all .txt files in the folder\n",
    "txt_files = glob.glob(os.path.join(path, '*.txt'))\n",
    "\n",
    "# Define column names and their widths\n",
    "col_names = ['target_name', 'accession_1', 'query_name', 'accession_2', \n",
    "             'E-value_1', 'score_1', 'bias_1', 'E-value_2', 'score_2', \n",
    "             'bias_2', 'exp', 'reg', 'clu', 'ov', 'env', 'dom', 'rep', \n",
    "             'inc', 'description']\n",
    "\n",
    "col_widths = [31, 11, 21, 11, 9, 7, 7, 9, 7, 7, 5, 5, 4, 4, 4, 4, 4, 4, 100]\n",
    "\n",
    "concatenated_df_dom = pd.DataFrame()\n",
    "for file_path in txt_files:\n",
    "# Read the file into a DataFrame\n",
    "    df = pd.read_fwf(file_path, widths=col_widths, names=col_names, skiprows=5,skipfooter=10)\n",
    "    concatenated_df_dom = pd.concat([df, concatenated_df_dom], ignore_index=True)\n",
    "\n",
    "concatenated_df_dom['D_classes'] = concatenated_df_dom['query_name'].str.split('_').str[1]\n",
    "\n",
    "# Sort the DataFrame based on 'E-value_1' column in ascending order\n",
    "df_sorted_dom = concatenated_df_dom.sort_values(by='E-value_1')\n",
    "\n",
    "# Keep the row with the smallest 'E-value_1'\n",
    "df_unique_dom = df_sorted_dom.drop_duplicates(subset='target_name', keep='first')\n",
    "\n",
    "# Display the DataFrame with unique target prefixes based on smallest 'E-value_1'\n",
    "df_unique_dom = df_unique_dom[df_unique_dom['E-value_1']< 10e-10]\n",
    "df_unique_dom['accession_code'] = df_unique_dom['target_name'].str.split('|').str.get(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8dd3013-fdac-4f0b-b3de-e55ca2c57bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_unique, df_unique_dom, on='accession_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b6f30c-3054-4aa4-b5ba-d1bab32d5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['host'] = merged_df['description_x'].str.split(\"OS=\").str[1].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2db55957-ecab-4a9d-bb63-b8399eb2bac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phage Name: Salmonella phage vB_SalM_ABTNLsp5.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def find_phage_name(uniprot_id):\n",
    "    url = f'https://rest.uniprot.org/uniprotkb/{uniprot_id}.txt'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=1000)\n",
    "        response.raise_for_status()\n",
    "        text = response.text\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error: Unable to retrieve information from {url}\")\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "        return None\n",
    "    except requests.exceptions.ConnectionError as err:\n",
    "        print(f\"Connection error: {err}\")\n",
    "        return None\n",
    "    \n",
    "    if text:\n",
    "        # Define the pattern to extract the line that starts with \"OS\"\n",
    "        os_pattern = r'^OS\\s+(.+)$'\n",
    "        \n",
    "        # Search for the line that starts with \"OS\" in the response text\n",
    "        os_match = re.search(os_pattern, text, re.MULTILINE)\n",
    "        \n",
    "        if os_match:\n",
    "            os_line = os_match.group(1)  # Extract the matched line content\n",
    "            \n",
    "            # Extract the phage name\n",
    "            phage_name = os_line.split('(')[0].strip()\n",
    "            return phage_name\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "uniprot_id = \"A0A7S9XES8\"  # Replace this with your desired UniProt ID\n",
    "phage_name = find_phage_name(uniprot_id)\n",
    "print(\"Phage Name:\", phage_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97bb7aa9-53fb-45bb-bc74-c25249c7aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 accession codes so far...\n",
      "Processed 200 accession codes so far...\n",
      "Processed 300 accession codes so far...\n",
      "Processed 400 accession codes so far...\n",
      "Processed 500 accession codes so far...\n",
      "Processed 600 accession codes so far...\n",
      "Processed 700 accession codes so far...\n",
      "Processed 800 accession codes so far...\n",
      "Processed 900 accession codes so far...\n",
      "Processed 1000 accession codes so far...\n",
      "Processed 1100 accession codes so far...\n",
      "Processed 1200 accession codes so far...\n",
      "Processed 1300 accession codes so far...\n",
      "Processed 1400 accession codes so far...\n",
      "Processed 1500 accession codes so far...\n",
      "Processed 1600 accession codes so far...\n",
      "Processed 1700 accession codes so far...\n",
      "Processed 1800 accession codes so far...\n",
      "Processed 1900 accession codes so far...\n",
      "Processed 2000 accession codes so far...\n",
      "Processed 2100 accession codes so far...\n",
      "Processed 2200 accession codes so far...\n",
      "Processed 2300 accession codes so far...\n",
      "Processed 2400 accession codes so far...\n",
      "Processed 2500 accession codes so far...\n",
      "Processed 2600 accession codes so far...\n",
      "Processed 2700 accession codes so far...\n",
      "Processed 2800 accession codes so far...\n",
      "Processed 2900 accession codes so far...\n",
      "Processed 3000 accession codes so far...\n",
      "Processed 3100 accession codes so far...\n",
      "Connection error: HTTPSConnectionPool(host='rest.uniprot.org', port=443): Max retries exceeded with url: /uniprotkb/A0AAD2Q020.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16c769990>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Processed 3200 accession codes so far...\n",
      "Processed 3300 accession codes so far...\n",
      "Processed 3400 accession codes so far...\n",
      "Processed 3500 accession codes so far...\n",
      "Processed 3600 accession codes so far...\n",
      "Processed 3700 accession codes so far...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name_x</th>\n",
       "      <th>accession_1_x</th>\n",
       "      <th>query_name_x</th>\n",
       "      <th>accession_2_x</th>\n",
       "      <th>E-value_1_x</th>\n",
       "      <th>score_1_x</th>\n",
       "      <th>bias_1_x</th>\n",
       "      <th>E-value_2_x</th>\n",
       "      <th>score_2_x</th>\n",
       "      <th>bias_2_x</th>\n",
       "      <th>...</th>\n",
       "      <th>clu_y</th>\n",
       "      <th>ov_y</th>\n",
       "      <th>env_y</th>\n",
       "      <th>dom_y</th>\n",
       "      <th>rep_y</th>\n",
       "      <th>inc_y</th>\n",
       "      <th>description_y</th>\n",
       "      <th>D_classes</th>\n",
       "      <th>host</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr|A0A653FW15|A0A653FW15_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2706.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2706.3</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Phage tail fiber protein OS=Escherichia phage ...</td>\n",
       "      <td>D9</td>\n",
       "      <td>Escherichia</td>\n",
       "      <td>Escherichia phage Gluttony_ev152.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr|A0A5Q2F504|A0A5Q2F504_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1033.8</td>\n",
       "      <td>56.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Long tail fiber proximal subunit OS=Klebsiella...</td>\n",
       "      <td>D38</td>\n",
       "      <td>Klebsiella</td>\n",
       "      <td>Klebsiella phage JIPh_Kp122.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr|A0A482N4I6|A0A482N4I6_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_4</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1764.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1764.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber protein OS=Escherichia phage vB_Eco...</td>\n",
       "      <td>D9</td>\n",
       "      <td>Escherichia</td>\n",
       "      <td>Escherichia phage vB_EcoS_WF5505.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr|A0A0K1Y530|A0A0K1Y530_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1042.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.900000e-298</td>\n",
       "      <td>990.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Long-tail fiber proximal subunit domain-contai...</td>\n",
       "      <td>D38</td>\n",
       "      <td>Klebsiella</td>\n",
       "      <td>Klebsiella phage JD18.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr|A0A7I8V5N5|A0A7I8V5N5_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1042.3</td>\n",
       "      <td>56.9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1035.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Long tail fiber proximal subunit OS=Klebsiella...</td>\n",
       "      <td>D38</td>\n",
       "      <td>Klebsiella</td>\n",
       "      <td>Klebsiella phage vB_KpnM_311F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>tr|A0AAE7VAA9|A0AAE7VAA9_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_12</td>\n",
       "      <td>-</td>\n",
       "      <td>2.800000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber protein OS=Escherichia phage vB_Eco...</td>\n",
       "      <td>D7</td>\n",
       "      <td>Escherichia</td>\n",
       "      <td>Escherichia phage vB_EcoS_Sponge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>tr|A0AAE7R9U8|A0AAE7R9U8_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_16</td>\n",
       "      <td>-</td>\n",
       "      <td>5.200000e-10</td>\n",
       "      <td>38.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.700000e-10</td>\n",
       "      <td>37.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bacteriophage T7 tail fibre protein-like N-ter...</td>\n",
       "      <td>D66</td>\n",
       "      <td>Synechococcus</td>\n",
       "      <td>Synechococcus phage S-SRP02.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>tr|A0A976SFM4|A0A976SFM4_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_1</td>\n",
       "      <td>-</td>\n",
       "      <td>5.300000e-10</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.500000e-10</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber protein OS=Vibrio phage VPMCC14 OX=...</td>\n",
       "      <td>D68</td>\n",
       "      <td>Vibrio</td>\n",
       "      <td>Vibrio phage VPMCC14.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>tr|U3TM45|U3TM45_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>6.100000e-10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.100000e-10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Putative tail fiber protein OS=Ralstonia phage...</td>\n",
       "      <td>D40</td>\n",
       "      <td>Ralstonia</td>\n",
       "      <td>Ralstonia phage RSB3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>tr|A0AAD1V9Y2|A0AAD1V9Y2_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_11</td>\n",
       "      <td>-</td>\n",
       "      <td>9.500000e-10</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.500000e-10</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Side tail fiber protein from bacteriophage ori...</td>\n",
       "      <td>D72</td>\n",
       "      <td>Acinetobacter</td>\n",
       "      <td>Acinetobacter phage MD-2021a.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3727 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       target_name_x accession_1_x query_name_x accession_2_x  \\\n",
       "0     tr|A0A653FW15|A0A653FW15_9CAUD             -    cluster_3             -   \n",
       "1     tr|A0A5Q2F504|A0A5Q2F504_9CAUD             -    cluster_0             -   \n",
       "2     tr|A0A482N4I6|A0A482N4I6_9CAUD             -    cluster_4             -   \n",
       "3     tr|A0A0K1Y530|A0A0K1Y530_9CAUD             -    cluster_0             -   \n",
       "4     tr|A0A7I8V5N5|A0A7I8V5N5_9CAUD             -    cluster_0             -   \n",
       "...                              ...           ...          ...           ...   \n",
       "3722  tr|A0AAE7VAA9|A0AAE7VAA9_9CAUD             -   cluster_12             -   \n",
       "3723  tr|A0AAE7R9U8|A0AAE7R9U8_9CAUD             -   cluster_16             -   \n",
       "3724  tr|A0A976SFM4|A0A976SFM4_9CAUD             -    cluster_1             -   \n",
       "3725          tr|U3TM45|U3TM45_9CAUD             -    cluster_0             -   \n",
       "3726  tr|A0AAD1V9Y2|A0AAD1V9Y2_9CAUD             -   cluster_11             -   \n",
       "\n",
       "       E-value_1_x  score_1_x  bias_1_x    E-value_2_x  score_2_x  bias_2_x  \\\n",
       "0     0.000000e+00     2706.5      20.9   0.000000e+00     2706.3      20.9   \n",
       "1     0.000000e+00     1040.0      56.7   0.000000e+00     1033.8      56.7   \n",
       "2     0.000000e+00     1764.3      13.7   0.000000e+00     1764.1      13.7   \n",
       "3     0.000000e+00     1042.3      55.0  7.900000e-298      990.7      42.0   \n",
       "4     0.000000e+00     1042.3      56.9   0.000000e+00     1035.8      56.9   \n",
       "...            ...        ...       ...            ...        ...       ...   \n",
       "3722  2.800000e-10       38.1       1.0   2.800000e-10       38.1       1.0   \n",
       "3723  5.200000e-10       38.2       6.1   8.700000e-10       37.4       6.1   \n",
       "3724  5.300000e-10       38.7       0.0   7.500000e-10       38.2       0.0   \n",
       "3725  6.100000e-10       37.0       3.1   6.100000e-10       37.0       3.1   \n",
       "3726  9.500000e-10       38.4       2.1   9.500000e-10       38.4       2.1   \n",
       "\n",
       "      ...  clu_y  ov_y  env_y  dom_y  rep_y  inc_y  \\\n",
       "0     ...      0     0      2      2      1      1   \n",
       "1     ...      2     3      5      5      5      4   \n",
       "2     ...      0     0      3      3      1      1   \n",
       "3     ...      2     3      5      5      5      4   \n",
       "4     ...      2     3      5      5      5      4   \n",
       "...   ...    ...   ...    ...    ...    ...    ...   \n",
       "3722  ...      1     0      2      2      1      1   \n",
       "3723  ...      1     0      1      1      1      1   \n",
       "3724  ...      0     0      1      1      1      1   \n",
       "3725  ...      0     0      2      2      2      1   \n",
       "3726  ...      0     0      3      3      1      1   \n",
       "\n",
       "                                          description_y  D_classes  \\\n",
       "0     Phage tail fiber protein OS=Escherichia phage ...         D9   \n",
       "1     Long tail fiber proximal subunit OS=Klebsiella...        D38   \n",
       "2     Tail fiber protein OS=Escherichia phage vB_Eco...         D9   \n",
       "3     Long-tail fiber proximal subunit domain-contai...        D38   \n",
       "4     Long tail fiber proximal subunit OS=Klebsiella...        D38   \n",
       "...                                                 ...        ...   \n",
       "3722  Tail fiber protein OS=Escherichia phage vB_Eco...         D7   \n",
       "3723  Bacteriophage T7 tail fibre protein-like N-ter...        D66   \n",
       "3724  Tail fiber protein OS=Vibrio phage VPMCC14 OX=...        D68   \n",
       "3725  Putative tail fiber protein OS=Ralstonia phage...        D40   \n",
       "3726  Side tail fiber protein from bacteriophage ori...        D72   \n",
       "\n",
       "               host                              Names  \n",
       "0       Escherichia  Escherichia phage Gluttony_ev152.  \n",
       "1        Klebsiella       Klebsiella phage JIPh_Kp122.  \n",
       "2       Escherichia  Escherichia phage vB_EcoS_WF5505.  \n",
       "3        Klebsiella             Klebsiella phage JD18.  \n",
       "4        Klebsiella     Klebsiella phage vB_KpnM_311F.  \n",
       "...             ...                                ...  \n",
       "3722    Escherichia  Escherichia phage vB_EcoS_Sponge.  \n",
       "3723  Synechococcus       Synechococcus phage S-SRP02.  \n",
       "3724         Vibrio              Vibrio phage VPMCC14.  \n",
       "3725      Ralstonia              Ralstonia phage RSB3.  \n",
       "3726  Acinetobacter      Acinetobacter phage MD-2021a.  \n",
       "\n",
       "[3727 rows x 44 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "phage_names = {}\n",
    "counter = 0\n",
    "\n",
    "def process_accession_code_name(accession_code):\n",
    "    return accession_code, find_phage_name(accession_code)\n",
    "\n",
    "# Specify the number of workers for parallel processing\n",
    "num_workers = 12  # Adjust this based on your machine's capabilities\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks for each accession code\n",
    "    futures = {executor.submit(process_accession_code_name, acc): acc for acc in merged_df['accession_code']}\n",
    "    \n",
    "    # Process completed futures as they finish\n",
    "    for future in as_completed(futures):\n",
    "        accession_code, name = future.result()\n",
    "        \n",
    "        # Add the result to the dictionary\n",
    "        phage_names[accession_code] = name\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "        \n",
    "        # Print a progress message every 100 processed accession codes\n",
    "        if counter % 100 == 0:\n",
    "            print(f\"Processed {counter} accession codes so far...\")\n",
    "\n",
    "# Now, phage_names is a dictionary mapping accession_code to phage_name\n",
    "#print(phage_names)\n",
    "\n",
    "\n",
    "# Assuming phage_names is your dictionary mapping accession codes to phage names\n",
    "merged_df['Names'] = merged_df['accession_code'].map(phage_names)\n",
    "merged_df['Names']=merged_df['Names'].fillna('noname')\n",
    "# Display the dataframe to check if it was updated correctly\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07399a6a-c8f4-43e8-9f33-c3d022a327d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_name_x', 'accession_1_x', 'query_name_x', 'accession_2_x',\n",
       "       'E-value_1_x', 'score_1_x', 'bias_1_x', 'E-value_2_x', 'score_2_x',\n",
       "       'bias_2_x', 'exp_x', 'reg_x', 'clu_x', 'ov_x', 'env_x', 'dom_x',\n",
       "       'rep_x', 'inc_x', 'description_x', 'TC', 'accession_code',\n",
       "       'subfamilies', 'target_name_y', 'accession_1_y', 'query_name_y',\n",
       "       'accession_2_y', 'E-value_1_y', 'score_1_y', 'bias_1_y', 'E-value_2_y',\n",
       "       'score_2_y', 'bias_2_y', 'exp_y', 'reg_y', 'clu_y', 'ov_y', 'env_y',\n",
       "       'dom_y', 'rep_y', 'inc_y', 'description_y', 'D_classes', 'host',\n",
       "       'Names'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accccf25-e1f8-4d57-a54c-cc9fe576f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('./data/atlas_tc_dclasses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31e84440-f0f2-473a-b592-dc453b4f7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipysigma import Sigma\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataframe is already loaded and named 'merged_df'\n",
    "# Step 1: Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Generate the tab20 palette using Seaborn\n",
    "palette = sns.color_palette(\"tab20\", 20)  # Generate 20 distinct colors (for TC0 to TC17, plus two more)\n",
    "\n",
    "# Create a dictionary to map TC categories to colors\n",
    "tc_palette = {f'TC{i}': f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})' for i, (r, g, b) in enumerate(palette[:18])}\n",
    "\n",
    "# Add colors for 'family' and 'domain' categories\n",
    "tc_palette['family'] = f'rgb({int(palette[18][0]*255)}, {int(palette[18][1]*255)}, {int(palette[18][2]*255)})'\n",
    "tc_palette['domain'] = f'rgb({int(palette[19][0]*255)}, {int(palette[19][1]*255)}, {int(palette[19][2]*255)})'\n",
    "\n",
    "# Step 2: Add edges between TCs, subfamilies, and D_classes based on shared occurrences in rows\n",
    "for index, row in merged_df.iterrows():\n",
    "    tc = row['TC']\n",
    "    subfamily = row['subfamilies']\n",
    "    domains = row['D_classes']\n",
    "    names = row['Names']\n",
    "    evalue_tc = row['E-value_1_x']\n",
    "    evalue_D = row['E-value_1_y']\n",
    "    \n",
    "    # Add nodes for TC, subfamily, domains, and names\n",
    "    G.add_node(tc, type='TC', tc_category=tc)\n",
    "    G.add_node(subfamily, type='subfamily or family', tc_category='family')\n",
    "    G.add_node(domains, type='D_classes', tc_category='domain')\n",
    "    G.add_node(names, type='Names', tc_category='Names')\n",
    "    \n",
    "    # Calculate weights for edges\n",
    "    weight_tc_subfamily = len(merged_df[(merged_df['TC'] == tc) & (merged_df['subfamilies'] == subfamily)])\n",
    "    weight_tc_domains = len(merged_df[(merged_df['TC'] == tc) & (merged_df['D_classes'] == domains)])\n",
    "    weight_domains_subfamily = len(merged_df[(merged_df['D_classes'] == domains) & (merged_df['subfamilies'] == subfamily)])\n",
    "\n",
    "    # Add edges with weights and evalues only where applicable\n",
    "    G.add_edge(tc, subfamily, weight=weight_tc_subfamily)  # No evalue\n",
    "    G.add_edge(tc, domains, weight=weight_tc_domains)       # No evalue\n",
    "    G.add_edge(domains, subfamily, weight=weight_domains_subfamily)  # No evalue\n",
    "    G.add_edge(subfamily, names)                            # No evalue\n",
    "    G.add_edge(domains, names, evalue=evalue_D)             # Only add evalue where applicable\n",
    "    G.add_edge(tc, names, evalue=evalue_tc)                 # Only add evalue where applicable\n",
    "\n",
    "# Step 3: Assign degrees to nodes for size scaling\n",
    "for node in G.nodes():\n",
    "    G.nodes[node]['degree'] = G.degree(node)\n",
    "    G.nodes[node]['color'] = tc_palette.get(G.nodes[node]['tc_category'], 'grey')  # Default to grey if no category color\n",
    "\n",
    "# Displaying the graph with ipysigma using the custom palette\n",
    "Sigma(\n",
    "    G, \n",
    "    node_color=\"color\",\n",
    "    node_size=\"degree\",\n",
    "    node_size_range=(3, 20),\n",
    "    edge_color='grey',\n",
    "    edge_size='weight',\n",
    "    edge_size_range=(1, 30),\n",
    "    node_label='tc_category',\n",
    "    default_node_color='grey',\n",
    "    edge_label='evalue'  # Show evalue as the edge label\n",
    ")\n",
    "\n",
    "\n",
    "Sigma.write_html(\n",
    "    G,\n",
    "    './data/dataset_ncbi_domains.html',\n",
    "    fullscreen=True,\n",
    "    node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "    node_color_palette=tc_palette,\n",
    "    node_metrics=['louvain'],\n",
    "    node_size_range=(3, 30),\n",
    "    max_categorical_colors=20,\n",
    "    edge_size='weight',\n",
    "    edge_size_range=(1, 30),\n",
    "    edge_label='evalue',\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    default_node_label_size=24,\n",
    "    node_size='degree'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82416b55-b39a-42a8-8135-6ac5ce2f1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = merged_df.head(2)\n",
    "\n",
    "\n",
    "# Assuming your dataframe is already loaded and named 'merged_df'\n",
    "# Step 1: Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Generate the tab20 palette using Seaborn\n",
    "palette = sns.color_palette(\"tab20\", 20)  # Generate 20 distinct colors (for TC0 to TC17, plus two more)\n",
    "\n",
    "# Create a dictionary to map TC categories to colors\n",
    "tc_palette = {f'TC{i}': f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})' for i, (r, g, b) in enumerate(palette[:18])}\n",
    "\n",
    "# Add colors for 'family' and 'domain' categories\n",
    "tc_palette['family'] = f'rgb({int(palette[18][0]*255)}, {int(palette[18][1]*255)}, {int(palette[18][2]*255)})'\n",
    "tc_palette['domain'] = f'rgb({int(palette[19][0]*255)}, {int(palette[19][1]*255)}, {int(palette[19][2]*255)})'\n",
    "\n",
    "# Step 2: Add edges between TCs, subfamilies, and D_classes based on shared occurrences in rows\n",
    "for index, row in subset_df.iterrows():\n",
    "    tc = row['TC']\n",
    "    subfamily = row['subfamilies']\n",
    "    domains = row['D_classes']\n",
    "    names = row['Names']\n",
    "    # Add nodes for TC, subfamily, and domains\n",
    "    G.add_node(tc, type='TC', tc_category=tc)  # Assign the actual TC value for coloring\n",
    "    G.add_node(subfamily, type='subfamily or family', tc_category='family')\n",
    "    G.add_node(domains, type='D_classes', tc_category='domain')\n",
    "    G.add_node(names, type='Names', tc_category='Names')\n",
    "    \n",
    "    # Calculate weights for edges\n",
    "    weight_tc_subfamily = len(subset_df[(subset_df['TC'] == tc) & (subset_df['subfamilies'] == subfamily)])\n",
    "    weight_tc_domains = len(subset_df[(subset_df['TC'] == tc) & (subset_df['D_classes'] == domains)])\n",
    "    weight_domains_subfamily = len(subset_df[(subset_df['D_classes'] == domains) & (subset_df['subfamilies'] == subfamily)])\n",
    "\n",
    "    # Add edges with weights\n",
    "    G.add_edge(tc, subfamily, weight=weight_tc_subfamily)\n",
    "    G.add_edge(tc, domains, weight=weight_tc_domains)\n",
    "    G.add_edge(domains, subfamily, weight=weight_domains_subfamily)\n",
    "    G.add_edge(subfamily, names)\n",
    "    G.add_edge(domains, names)\n",
    "    G.add_edge(tc, names)\n",
    "# Displaying the graph with ipysigma using the custom palette\n",
    "Sigma(G, \n",
    "      node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "      node_color_palette=tc_palette, # Use the custom TC palette\n",
    "      node_size=\"degree\",            # Set node size by degree\n",
    "      node_size_range=(3, 20),       # Adjust size range if needed\n",
    "      edge_color='grey',             # Default edge color\n",
    "      edge_size='weight',            # Adjust edge thickness based on weight\n",
    "      edge_size_range=(1, 30),       # Adjust size range if needed\n",
    "      node_label='tc_category',      # Display TC categories as node labels\n",
    "      default_node_color='grey'      # Default color for nodes not in the TC palette\n",
    ")\n",
    "\n",
    "\n",
    "Sigma.write_html(\n",
    "    G,\n",
    "    './data/dataset_ncbi_domains_sub.html',\n",
    "    fullscreen=True,\n",
    "    node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "    node_color_palette=tc_palette,\n",
    "    node_metrics=['louvain'],\n",
    "    node_size_range=(3, 30),\n",
    "    max_categorical_colors=20,\n",
    "    edge_size='weight',\n",
    "    edge_size_range=(1, 30),\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    default_node_label_size=24,\n",
    "    node_size=G.degree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc226db-f02c-4050-aa2f-8fa4abd71c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2abb5f478734d008c34caa2fa822e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sigma(nx.Graph with 2,264 nodes and 9,215 edges)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipysigma import Sigma\n",
    "from IPython.display import display\n",
    "\n",
    "# Assuming your dataframe is already loaded and named 'merged_df'\n",
    "# Step 1: Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Generate the tab20 palette using Seaborn\n",
    "palette = sns.color_palette(\"tab20\", 20)  # Generate 20 distinct colors (for TC0 to TC17, plus two more)\n",
    "\n",
    "# Create a dictionary to map TC categories to colors\n",
    "tc_palette = {f'TC{i}': f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})' for i, (r, g, b) in enumerate(palette[:18])}\n",
    "\n",
    "# Add colors for 'family' and 'domain' categories\n",
    "tc_palette['family'] = f'rgb({int(palette[18][0]*255)}, {int(palette[18][1]*255)}, {int(palette[18][2]*255)})'\n",
    "tc_palette['domain'] = f'rgb({int(palette[19][0]*255)}, {int(palette[19][1]*255)}, {int(palette[19][2]*255)})'\n",
    "\n",
    "# Step 2: Add nodes and edges between TCs, subfamilies, and D_classes based on shared occurrences in rows\n",
    "for index, row in merged_df.iterrows():\n",
    "    tc = row['TC']\n",
    "    subfamily = row['subfamilies']\n",
    "    domains = row['D_classes']\n",
    "    names = row['Names']\n",
    "    \n",
    "    # Add nodes for TC, subfamily, and domains\n",
    "    G.add_node(tc, type='TC', tc_category=tc)  # Assign the actual TC value for coloring\n",
    "    G.add_node(subfamily, type='subfamily or family', tc_category='family')\n",
    "    G.add_node(domains, type='D_classes', tc_category='domain')\n",
    "    G.add_node(names, type='Names', tc_category='Names')\n",
    "    \n",
    "    # Add edges with default weight of 1\n",
    "    G.add_edge(tc, subfamily)\n",
    "    G.add_edge(tc, domains)\n",
    "    G.add_edge(domains, subfamily)\n",
    "    G.add_edge(subfamily, names)\n",
    "    G.add_edge(domains, names)\n",
    "    G.add_edge(tc, names)\n",
    "\n",
    "# Step 3: Initialize and display the Sigma widget\n",
    "sigma = Sigma(G, \n",
    "    node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "    node_color_palette=tc_palette,\n",
    "    node_metrics=['louvain'],\n",
    "    node_size_range=(3, 10),\n",
    "    max_categorical_colors=20,\n",
    "    edge_size='weight',\n",
    "    edge_size_range=(1, 30),\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    default_node_label_size=24,\n",
    "    node_size=G.degree    # Default color for nodes not in the TC palette\n",
    ")\n",
    "\n",
    "# Display the Sigma widget first\n",
    "display(sigma)\n",
    "\n",
    "# Now render a snapshot after the widget is displayed\n",
    "#sigma.render_snapshot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f20b3476-27cf-470c-b60e-ed23dcacf000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 accession codes so far...\n",
      "Processed 200 accession codes so far...\n",
      "Processed 300 accession codes so far...\n",
      "Processed 400 accession codes so far...\n",
      "Processed 500 accession codes so far...\n",
      "Processed 600 accession codes so far...\n",
      "Connection error: HTTPSConnectionPool(host='rest.uniprot.org', port=443): Max retries exceeded with url: /uniprotkb/A0A345ARD4.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x17f9ac790>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Processed 700 accession codes so far...\n",
      "Processed 800 accession codes so far...\n",
      "Processed 900 accession codes so far...\n",
      "Processed 1000 accession codes so far...\n",
      "Processed 1100 accession codes so far...\n",
      "Processed 1200 accession codes so far...\n",
      "Processed 1300 accession codes so far...\n",
      "Processed 1400 accession codes so far...\n",
      "Processed 1500 accession codes so far...\n",
      "Processed 1600 accession codes so far...\n",
      "Processed 1700 accession codes so far...\n",
      "Processed 1800 accession codes so far...\n",
      "Processed 1900 accession codes so far...\n",
      "Processed 2000 accession codes so far...\n",
      "Processed 2100 accession codes so far...\n",
      "Processed 2200 accession codes so far...\n",
      "Processed 2300 accession codes so far...\n",
      "Processed 2400 accession codes so far...\n",
      "Processed 2500 accession codes so far...\n",
      "Processed 2600 accession codes so far...\n",
      "Processed 2700 accession codes so far...\n",
      "Processed 2800 accession codes so far...\n",
      "Processed 2900 accession codes so far...\n",
      "Processed 3000 accession codes so far...\n",
      "Processed 3100 accession codes so far...\n",
      "Processed 3200 accession codes so far...\n",
      "Processed 3300 accession codes so far...\n",
      "Processed 3400 accession codes so far...\n",
      "Processed 3500 accession codes so far...\n",
      "Processed 3600 accession codes so far...\n",
      "Processed 3700 accession codes so far...\n",
      "Processed 3800 accession codes so far...\n",
      "Processed 3900 accession codes so far...\n",
      "Processed 4000 accession codes so far...\n",
      "Processed 4100 accession codes so far...\n",
      "Processed 4200 accession codes so far...\n",
      "Processed 4300 accession codes so far...\n",
      "Processed 4400 accession codes so far...\n",
      "Processed 4500 accession codes so far...\n",
      "Processed 4600 accession codes so far...\n",
      "Processed 4700 accession codes so far...\n",
      "Processed 4800 accession codes so far...\n",
      "Processed 4900 accession codes so far...\n",
      "Processed 5000 accession codes so far...\n",
      "Processed 5100 accession codes so far...\n",
      "Processed 5200 accession codes so far...\n",
      "Processed 5300 accession codes so far...\n",
      "Processed 5400 accession codes so far...\n",
      "Processed 5500 accession codes so far...\n",
      "Processed 5600 accession codes so far...\n",
      "Processed 5700 accession codes so far...\n",
      "Processed 5800 accession codes so far...\n",
      "Processed 5900 accession codes so far...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name</th>\n",
       "      <th>accession_1</th>\n",
       "      <th>query_name</th>\n",
       "      <th>accession_2</th>\n",
       "      <th>E-value_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>bias_1</th>\n",
       "      <th>E-value_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>bias_2</th>\n",
       "      <th>...</th>\n",
       "      <th>ov</th>\n",
       "      <th>env</th>\n",
       "      <th>dom</th>\n",
       "      <th>rep</th>\n",
       "      <th>inc</th>\n",
       "      <th>description</th>\n",
       "      <th>TC</th>\n",
       "      <th>accession_code</th>\n",
       "      <th>subfamilies</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr|A0A653FW15|A0A653FW15_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2706.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2706.3</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Phage tail fiber protein OS=Escherichia phage ...</td>\n",
       "      <td>TC3</td>\n",
       "      <td>A0A653FW15</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Escherichia phage Gluttony_ev152.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>tr|A0A5Q2F504|A0A5Q2F504_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1033.8</td>\n",
       "      <td>56.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Long tail fiber proximal subunit OS=Klebsiella...</td>\n",
       "      <td>TC0</td>\n",
       "      <td>A0A5Q2F504</td>\n",
       "      <td>Straboviridae</td>\n",
       "      <td>Klebsiella phage JIPh_Kp122.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>tr|A0A482N4I6|A0A482N4I6_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_4</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1764.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1764.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber protein OS=Escherichia phage vB_Eco...</td>\n",
       "      <td>TC4</td>\n",
       "      <td>A0A482N4I6</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Escherichia phage vB_EcoS_WF5505.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>tr|A0A0K1Y530|A0A0K1Y530_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1042.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.900000e-298</td>\n",
       "      <td>990.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Long-tail fiber proximal subunit domain-contai...</td>\n",
       "      <td>TC0</td>\n",
       "      <td>A0A0K1Y530</td>\n",
       "      <td>Straboviridae</td>\n",
       "      <td>Klebsiella phage JD18.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>tr|A0A7I8V5N5|A0A7I8V5N5_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1042.3</td>\n",
       "      <td>56.9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1035.8</td>\n",
       "      <td>56.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Long tail fiber proximal subunit OS=Klebsiella...</td>\n",
       "      <td>TC0</td>\n",
       "      <td>A0A7I8V5N5</td>\n",
       "      <td>Straboviridae</td>\n",
       "      <td>Klebsiella phage vB_KpnM_311F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>tr|A0A9E7LJA2|A0A9E7LJA2_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_7</td>\n",
       "      <td>-</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber OS=Escherichia phage EC105 OX=29369...</td>\n",
       "      <td>TC7</td>\n",
       "      <td>A0A9E7LJA2</td>\n",
       "      <td>Demerecviridae</td>\n",
       "      <td>Escherichia phage EC105.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>tr|A0A9E7IND2|A0A9E7IND2_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_7</td>\n",
       "      <td>-</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber OS=Escherichia phage EC104 OX=29369...</td>\n",
       "      <td>TC7</td>\n",
       "      <td>A0A9E7IND2</td>\n",
       "      <td>Demerecviridae</td>\n",
       "      <td>Escherichia phage EC104.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>tr|A0A9E7IDC4|A0A9E7IDC4_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_7</td>\n",
       "      <td>-</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.300000e-10</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tail fiber OS=Escherichia phage EC122 OX=29369...</td>\n",
       "      <td>TC7</td>\n",
       "      <td>A0A9E7IDC4</td>\n",
       "      <td>Demerecviridae</td>\n",
       "      <td>Escherichia phage EC122.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>tr|A0AAD1V9Y2|A0AAD1V9Y2_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_11</td>\n",
       "      <td>-</td>\n",
       "      <td>9.500000e-10</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.500000e-10</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Side tail fiber protein from bacteriophage ori...</td>\n",
       "      <td>TC11</td>\n",
       "      <td>A0AAD1V9Y2</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Acinetobacter phage MD-2021a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>tr|A0A4Y1NMW4|A0A4Y1NMW4_9CAUD</td>\n",
       "      <td>-</td>\n",
       "      <td>cluster_11</td>\n",
       "      <td>-</td>\n",
       "      <td>9.700000e-10</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.700000e-10</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Long tail fiber protein OS=Acinetobacter phage...</td>\n",
       "      <td>TC11</td>\n",
       "      <td>A0A4Y1NMW4</td>\n",
       "      <td>Straboviridae</td>\n",
       "      <td>Acinetobacter phage AM101.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5969 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         target_name accession_1  query_name accession_2  \\\n",
       "0     tr|A0A653FW15|A0A653FW15_9CAUD           -   cluster_3           -   \n",
       "923   tr|A0A5Q2F504|A0A5Q2F504_9CAUD           -   cluster_0           -   \n",
       "1844  tr|A0A482N4I6|A0A482N4I6_9CAUD           -   cluster_4           -   \n",
       "921   tr|A0A0K1Y530|A0A0K1Y530_9CAUD           -   cluster_0           -   \n",
       "920   tr|A0A7I8V5N5|A0A7I8V5N5_9CAUD           -   cluster_0           -   \n",
       "...                              ...         ...         ...         ...   \n",
       "2873  tr|A0A9E7LJA2|A0A9E7LJA2_9CAUD           -   cluster_7           -   \n",
       "2872  tr|A0A9E7IND2|A0A9E7IND2_9CAUD           -   cluster_7           -   \n",
       "2871  tr|A0A9E7IDC4|A0A9E7IDC4_9CAUD           -   cluster_7           -   \n",
       "5662  tr|A0AAD1V9Y2|A0AAD1V9Y2_9CAUD           -  cluster_11           -   \n",
       "5663  tr|A0A4Y1NMW4|A0A4Y1NMW4_9CAUD           -  cluster_11           -   \n",
       "\n",
       "         E-value_1  score_1  bias_1      E-value_2  score_2  bias_2  ...  ov  \\\n",
       "0     0.000000e+00   2706.5    20.9   0.000000e+00   2706.3    20.9  ...   0   \n",
       "923   0.000000e+00   1040.0    56.7   0.000000e+00   1033.8    56.7  ...   0   \n",
       "1844  0.000000e+00   1764.3    13.7   0.000000e+00   1764.1    13.7  ...   0   \n",
       "921   0.000000e+00   1042.3    55.0  7.900000e-298    990.7    42.0  ...   0   \n",
       "920   0.000000e+00   1042.3    56.9   0.000000e+00   1035.8    56.9  ...   0   \n",
       "...            ...      ...     ...            ...      ...     ...  ...  ..   \n",
       "2873  7.300000e-10     38.1     0.2   7.300000e-10     38.1     0.2  ...   0   \n",
       "2872  7.300000e-10     38.1     0.2   7.300000e-10     38.1     0.2  ...   0   \n",
       "2871  7.300000e-10     38.1     0.2   7.300000e-10     38.1     0.2  ...   0   \n",
       "5662  9.500000e-10     38.4     2.1   9.500000e-10     38.4     2.1  ...   0   \n",
       "5663  9.700000e-10     38.3     2.1   9.700000e-10     38.3     2.1  ...   0   \n",
       "\n",
       "      env  dom  rep  inc                                        description  \\\n",
       "0       1    1    1    1  Phage tail fiber protein OS=Escherichia phage ...   \n",
       "923     1    1    1    1  Long tail fiber proximal subunit OS=Klebsiella...   \n",
       "1844    1    1    1    1  Tail fiber protein OS=Escherichia phage vB_Eco...   \n",
       "921     2    2    2    2  Long-tail fiber proximal subunit domain-contai...   \n",
       "920     1    1    1    1  Long tail fiber proximal subunit OS=Klebsiella...   \n",
       "...   ...  ...  ...  ...                                                ...   \n",
       "2873    2    2    1    1  Tail fiber OS=Escherichia phage EC105 OX=29369...   \n",
       "2872    2    2    1    1  Tail fiber OS=Escherichia phage EC104 OX=29369...   \n",
       "2871    2    2    1    1  Tail fiber OS=Escherichia phage EC122 OX=29369...   \n",
       "5662    4    4    2    1  Side tail fiber protein from bacteriophage ori...   \n",
       "5663    4    4    2    1  Long tail fiber protein OS=Acinetobacter phage...   \n",
       "\n",
       "        TC  accession_code     subfamilies                              Names  \n",
       "0      TC3      A0A653FW15    unclassified  Escherichia phage Gluttony_ev152.  \n",
       "923    TC0      A0A5Q2F504   Straboviridae       Klebsiella phage JIPh_Kp122.  \n",
       "1844   TC4      A0A482N4I6    unclassified  Escherichia phage vB_EcoS_WF5505.  \n",
       "921    TC0      A0A0K1Y530   Straboviridae             Klebsiella phage JD18.  \n",
       "920    TC0      A0A7I8V5N5   Straboviridae     Klebsiella phage vB_KpnM_311F.  \n",
       "...    ...             ...             ...                                ...  \n",
       "2873   TC7      A0A9E7LJA2  Demerecviridae           Escherichia phage EC105.  \n",
       "2872   TC7      A0A9E7IND2  Demerecviridae           Escherichia phage EC104.  \n",
       "2871   TC7      A0A9E7IDC4  Demerecviridae           Escherichia phage EC122.  \n",
       "5662  TC11      A0AAD1V9Y2    unclassified      Acinetobacter phage MD-2021a.  \n",
       "5663  TC11      A0A4Y1NMW4   Straboviridae         Acinetobacter phage AM101.  \n",
       "\n",
       "[5969 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "phage_names = {}\n",
    "counter = 0\n",
    "\n",
    "def process_accession_code_name(accession_code):\n",
    "    return accession_code, find_phage_name(accession_code)\n",
    "\n",
    "# Specify the number of workers for parallel processing\n",
    "num_workers = 12  # Adjust this based on your machine's capabilities\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks for each accession code\n",
    "    futures = {executor.submit(process_accession_code_name, acc): acc for acc in df_sorted['accession_code']}\n",
    "    \n",
    "    # Process completed futures as they finish\n",
    "    for future in as_completed(futures):\n",
    "        accession_code, name = future.result()\n",
    "        \n",
    "        # Add the result to the dictionary\n",
    "        phage_names[accession_code] = name\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "        \n",
    "        # Print a progress message every 100 processed accession codes\n",
    "        if counter % 100 == 0:\n",
    "            print(f\"Processed {counter} accession codes so far...\")\n",
    "\n",
    "# Now, phage_names is a dictionary mapping accession_code to phage_name\n",
    "#print(phage_names)\n",
    "\n",
    "\n",
    "# Assuming phage_names is your dictionary mapping accession codes to phage names\n",
    "df_sorted['Names'] = df_sorted['accession_code'].map(phage_names)\n",
    "df_sorted['Names']=df_sorted['Names'].fillna('noname')\n",
    "# Display the dataframe to check if it was updated correctly\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12f2b110-7292-4d23-ade7-cedd99ce757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_sorted[df_sorted['E-value_2'] < 10e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bc35df8e-a91a-4c32-90fa-0eb5ef011aca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subfamilies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subfamilies'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_sorted\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     23\u001b[0m     tc \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m     subfamily \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubfamilies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#domains = row['D_classes']\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     names \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNames\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subfamilies'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipysigma import Sigma\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataframe is already loaded and named 'merged_df'\n",
    "# Step 1: Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Generate the tab20 palette using Seaborn\n",
    "palette = sns.color_palette(\"tab20\", 20)  # Generate 20 distinct colors (for TC0 to TC17, plus two more)\n",
    "\n",
    "# Create a dictionary to map TC categories to colors\n",
    "tc_palette = {f'TC{i}': f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})' for i, (r, g, b) in enumerate(palette[:18])}\n",
    "\n",
    "# Add colors for 'family' and 'domain' categories\n",
    "tc_palette['family'] = f'rgb({int(palette[18][0]*255)}, {int(palette[18][1]*255)}, {int(palette[18][2]*255)})'\n",
    "tc_palette['domain'] = f'rgb({int(palette[19][0]*255)}, {int(palette[19][1]*255)}, {int(palette[19][2]*255)})'\n",
    "\n",
    "# Step 2: Add edges between TCs, subfamilies, and D_classes based on shared occurrences in rows\n",
    "for index, row in df_sorted.iterrows():\n",
    "    tc = row['TC']\n",
    "    subfamily = row['subfamilies']\n",
    "    #domains = row['D_classes']\n",
    "    names = row['Names']\n",
    "    # Add nodes for TC, subfamily, and domains\n",
    "    G.add_node(tc, type='TC', tc_category=tc)  # Assign the actual TC value for coloring\n",
    "    G.add_node(subfamily, type='subfamily or family', tc_category='family')\n",
    "    #G.add_node(domains, type='D_classes', tc_category='domain')\n",
    "    G.add_node(names, type='Names', tc_category='Names')\n",
    "    \n",
    "    # Calculate weights for edges\n",
    "    weight_tc_subfamily = len(df_sorted[(df_sorted['TC'] == tc) & (df_sorted['subfamilies'] == subfamily)])\n",
    "    #weight_tc_domains = len(df_sorted[(df_sorted['TC'] == tc) & (df_sorted['D_classes'] == domains)])\n",
    "    #weight_domains_subfamily = len(df_sorted[(df_sorted['D_classes'] == domains) & (df_sorted['subfamilies'] == subfamily)])\n",
    "\n",
    "    # Add edges with weights\n",
    "    G.add_edge(tc, subfamily, weight=weight_tc_subfamily)\n",
    "    G.add_edge(tc, domains, weight=weight_tc_domains)\n",
    "    #G.add_edge(domains, subfamily, weight=weight_domains_subfamily)\n",
    "    G.add_edge(subfamily, names)\n",
    "    #G.add_edge(domains, names)\n",
    "    G.add_edge(tc, names)\n",
    "# Displaying the graph with ipysigma using the custom palette\n",
    "Sigma(G, \n",
    "      node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "      node_color_palette=tc_palette, # Use the custom TC palette\n",
    "      node_size=\"degree\",            # Set node size by degree\n",
    "      node_size_range=(3, 20),       # Adjust size range if needed\n",
    "      edge_color='grey',             # Default edge color\n",
    "      edge_size='weight',            # Adjust edge thickness based on weight\n",
    "      edge_size_range=(1, 30),       # Adjust size range if needed\n",
    "      node_label='tc_category',      # Display TC categories as node labels\n",
    "      default_node_color='grey'      # Default color for nodes not in the TC palette\n",
    ")\n",
    "\n",
    "\n",
    "Sigma.write_html(\n",
    "    G,\n",
    "    './dataset_ncbi.html',\n",
    "    fullscreen=True,\n",
    "    node_color=\"tc_category\",      # Color nodes by the 'tc_category' attribute\n",
    "    node_color_palette=tc_palette,\n",
    "    node_metrics=['louvain'],\n",
    "    node_size_range=(10, 100),\n",
    "    max_categorical_colors=20,\n",
    "    edge_size='weight',\n",
    "    edge_size_range=(1, 30),\n",
    "    default_edge_type='curve',\n",
    "    node_border_color_from='node',\n",
    "    default_node_label_size=24,\n",
    "    node_size=G.degree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24fe0f8e-ef49-444f-b542-310df6c12414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(Deprecated) Installing extensions with the jupyter labextension install command is now deprecated and will be removed in a future major version of JupyterLab.\n",
      "\n",
      "Users should manage prebuilt extensions with package managers like pip and conda, and extension authors are encouraged to distribute their extensions as prebuilt packages \u001b[0m\n",
      "/Users/shj152/anaconda3/lib/python3.11/site-packages/jupyterlab/debuglog.py:54: UserWarning: An error occurred.\n",
      "  warnings.warn(\"An error occurred.\")\n",
      "/Users/shj152/anaconda3/lib/python3.11/site-packages/jupyterlab/debuglog.py:55: UserWarning: ValueError: Please install Node.js and npm before continuing installation. You may be able to install Node.js from your package manager, from conda, or directly from the Node.js website (https://nodejs.org).\n",
      "  warnings.warn(msg[-1].strip())\n",
      "/Users/shj152/anaconda3/lib/python3.11/site-packages/jupyterlab/debuglog.py:56: UserWarning: See the log file for details: /var/folders/2p/8071jp1s2ml2vj_81_qt_5680000gn/T/jupyterlab-debug-en6dqtgu.log\n",
      "  warnings.warn(f\"See the log file for details: {log_path!s}\")\n"
     ]
    }
   ],
   "source": [
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "245d29d0-fd26-4260-99bc-36f0c6935e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50137a0a-c3bf-47b2-8c38-96912d8ad809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_name', 'accession_1', 'query_name', 'accession_2', 'E-value_1',\n",
       "       'score_1', 'bias_1', 'E-value_2', 'score_2', 'bias_2', 'exp', 'reg',\n",
       "       'clu', 'ov', 'env', 'dom', 'rep', 'inc', 'description', 'TC',\n",
       "       'new_encoded_TC_2', 'accession_code', 'subfamilies', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d343d-f712-4471-b598-9bc649313f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
